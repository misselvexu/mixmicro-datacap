{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"DataCap","text":"DataCap is integrated software for data transformation, integration, and visualization. Support a variety of data sources, file types, big data related database, relational database, NoSQL database, etc. Through the software can realize the management of multiple data sources, the data under the source of various operations conversion, making data charts, monitoring data sources and other functions.               Get Started             Download             Join Us On GitHub             View online examples"},{"location":"index.html#overview","title":"Overview","text":"<p> Datacap is fast, lightweight, intuitive system. </p> <ul> <li> <p>Powerful yet easy to use </p> <p>Quickly and easily integrate and explore your data, using simple SQL IDE.</p> </li> <li> <p>Integrates with modern databases</p> <p>DataCap can connect to any SQL based datasource through JDBC and native and http.</p> </li> <li> <p>Join DingDing</p> <p></p> </li> </ul>"},{"location":"index.html#supported-connectors","title":"Supported Connectors","text":""},{"location":"download.html","title":"Download","text":"The current Trino release is version . Learn more details from the release notes.  <ul> <li> <p> Server packages</p> <p>Utilize the <code>.tar.gz</code> package to manually deploy. See Installation datacap for complete install instructions.</p> <p></p> <p>datacap-server-1.8.0.tar.gz</p> </li> <li> <p> Command line client</p> <p>You can run queries using the interactive command line interface.</p> <p></p> <p>datacap-client-cli-1.8.0.jar</p> </li> <li> <p> More package</p> <p>See The source code to install for complete install instructions.</p> <p></p> <p>Source Code</p> </li> </ul> <ul> <li> <p>Community resources</p> <ul> <li>Chat On Slack: edurtio.slack.com</li> <li>Issues: GitHub issues</li> <li>DingTalk: 16160001608</li> </ul> </li> <li> <p>Getting help</p> <p>If you need help using or running dbm, please ask a question on Slack. Please report any issue you find with dbm.</p> </li> </ul>"},{"location":"powered_by.html","title":"Powered By","text":"Add Your or Company <p>Note</p> <p>There are many companies, individuals and open source organizations that use this program. Some of them are listed below.</p>"},{"location":"powered_by.html#open-project","title":"Open Project","text":"<ul> <li> <p> DataCap developer</p> <p>DataCap is integrated software for data transformation, integration and visualization.   Getting started</p> </li> </ul>"},{"location":"powered_by.html#personal-user","title":"Personal user","text":"<ul> <li> <p> qianmoQ</p> <p>Source code contributors who love open source projects.  Visit qianmoQ</p> </li> </ul>"},{"location":"developer_guide/env.html","title":"Development environment","text":"<p>The development environment is mainly divided into two services and a document module. The following is a detailed description of the construction of each service environment.</p> <p>Warning</p> <p>Before development, please import the format files of the code into the editor, they are in the <code>configure</code> directory</p>"},{"location":"developer_guide/env.html#server","title":"Server","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment","title":"Depends on the environment","text":"Environment Version Required <code>JDK</code> &gt;= 1.8 Need <code>Maven</code> &gt;= 3.5 Optional"},{"location":"developer_guide/env.html#source-code-preparation","title":"Source code preparation","text":"<p>Fork the code in the code warehouse and clone the code to the local, enter the source code directory</p> <pre><code>git clone git@github.com:&lt;GitHubUser&gt;/datacap.git\n</code></pre>"},{"location":"developer_guide/env.html#load-source-code","title":"Load source code","text":"<p>Open idea to load the project</p> <p></p> <p>After opening the project, the right menu displays the project directory</p> <p></p> <ul> <li><code>configure</code> Some configurations used by the project</li> <li><code>dist</code> Binary file storage path after the project is packaged</li> <li><code>docs</code> Project Documentation Source Code</li> <li><code>plugin</code> Project plug-in source code</li> <li><code>server</code> Project main service source code</li> <li><code>spi</code> Project plug-in integration core source code</li> <li><code>web</code> Project web front-end source code</li> </ul>"},{"location":"developer_guide/env.html#service-start","title":"Service start","text":"<p>Service startup needs to modify the specified configuration file directory</p> <p></p> <p>Add <code>--spring.config.location=</code> configuration in <code>Program arguments</code></p> <p>The content of the configuration file is the current project startup service configuration, and the configuration source code is in <code>server/src/main/etc/conf</code></p> <p>After the service is configured, it can be started. After the service is started, access <code>http://localhost:9096/</code></p>"},{"location":"developer_guide/env.html#web","title":"Web","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment_1","title":"Depends on the environment","text":"Environment Version Required <code>Node</code> &gt;= v16.x Need <code>Npm</code> &gt;= 7.x Need <p><code>console-fe</code> The web front-end source code is in this directory</p>"},{"location":"developer_guide/env.html#service-start_1","title":"Service start","text":"<ul> <li>Go to the source code directory</li> </ul> <pre><code>cd web/console-fe\n</code></pre> <ul> <li>Start service</li> </ul> <pre><code>yarn run dev\n</code></pre> <p>After the command is executed, the source code will be compiled, and something similar to the following will appear after compilation</p> <pre><code>...\nUse /* eslint-disable */ to ignore all warnings in a file.\n\nApp running at:\n- Local:   http://localhost:8080/ \n- Network: http://192.168.32.53:8080/\n\nNote that the development build is not optimized.\nTo create a production build, run yarn build.\n\nNo issues found.\n</code></pre> <p>Access <code>http://localhost:8080</code> through a browser to debug the source code, do not use the address returned by <code>Network</code></p>"},{"location":"developer_guide/env.html#docs","title":"Docs","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment_2","title":"Depends on the environment","text":"Environment Version Required <code>mkdocs</code> &gt;= 1.3.0 Need <p><code>docs/docs</code> Document source code is in this directory</p>"},{"location":"developer_guide/env.html#service-start_2","title":"Service start","text":"<ul> <li>Go to the source code directory</li> </ul> <pre><code>cd docs\n</code></pre> <ul> <li>Start service</li> </ul> <pre><code>mkdocs serve --dev-addr=0.0.0.0:8001\n</code></pre> <p>After the command is executed, the source code will be compiled, and something similar to the following will appear after compilation</p> <pre><code>...\nINFO     -  Documentation built in 1.07 seconds\nINFO     -  [13:16:03] Watching paths for changes: 'docs', 'mkdocs.yml'\nINFO     -  [13:16:03] Serving on http://0.0.0.0:8001/\nINFO     -  [13:16:03] Browser connected: http://0.0.0.0:8001/developer_guide/env.html\n</code></pre> <p>Access <code>http://0.0.0.0:8001</code> through a browser to debug the source code</p>"},{"location":"developer_guide/plugin.html","title":"Custom Plugin","text":"<p>When we need to integrate other plugins into this system, we can follow the steps in this article.</p> <p>Note</p> <p>How custom plugins are used We use the Kylin plugin as an example</p>"},{"location":"developer_guide/plugin.html#integrated-spi-module","title":"Integrated <code>spi</code> module","text":"<p>Add the following dependencies in the project's <code>pom.xml</code> file</p> <pre><code>&lt;!-- Add kylin jdbc related dependencies here --&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n&lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n&lt;version&gt;DATACAP-SPI_LAST_VERSION&lt;/version&gt;\n&lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p><code>&lt;build&gt;</code> and <code>&lt;properties&gt;</code> The stage is generally in accordance with the rules</p> <p>Warning</p> <p><code>DATACAP-SPI_LAST_VERSION</code> It is recommended that you change this value to the latest SPI version</p>"},{"location":"developer_guide/plugin.html#build-load-module-pluginmodule","title":"Build Load Module (PluginModule)","text":"<pre><code>package io.edurt.datacap.plugin.jdbc.kylin;\n\nimport com.google.inject.multibindings.Multibinder;\nimport io.edurt.datacap.spi.AbstractPluginModule;\nimport io.edurt.datacap.spi.Plugin;\nimport io.edurt.datacap.spi.PluginModule;\nimport io.edurt.datacap.spi.PluginType;\n\npublic class KylinPluginModule\nextends AbstractPluginModule\nimplements PluginModule\n{\n@Override\npublic String getName()\n{\nreturn \"Kylin\";\n}\n\n@Override\npublic PluginType getType()\n{\nreturn PluginType.SOURCE;\n}\n\n@Override\npublic AbstractPluginModule get()\n{\nreturn this;\n}\n\nprotected void configure()\n{\nMultibinder&lt;String&gt; module = Multibinder.newSetBinder(this.binder(), String.class);\nmodule.addBinding().toInstance(this.getClass().getSimpleName());\nMultibinder&lt;Plugin&gt; plugin = Multibinder.newSetBinder(this.binder(), Plugin.class);\nplugin.addBinding().to(KylinPlugin.class);\n}\n}\n</code></pre> <p><code>extends AbstractPluginModule</code> The module indicates that the class belongs to a plugin</p> <p><code>implements PluginModule</code> Some metadata implements the plug-ins required by the system</p>"},{"location":"developer_guide/plugin.html#configure","title":"<code>configure()</code>","text":"<pre><code>Multibinder&lt;Plugin&gt; plugin = Multibinder.newSetBinder(this.binder(), Plugin.class);\nplugin.addBinding().to(KylinPlugin.class);\n</code></pre> <p>The core here is that we want to bind and map the plugin we wrote into the system container</p>"},{"location":"developer_guide/plugin.html#build-adapter","title":"Build Adapter","text":"<pre><code>package io.edurt.datacap.plugin.jdbc.kylin;\n\nimport io.edurt.datacap.spi.adapter.JdbcAdapter;\nimport io.edurt.datacap.spi.connection.JdbcConnection;\n\npublic class KylinAdapter\nextends JdbcAdapter\n{\npublic KylinAdapter(JdbcConnection jdbcConnection)\n{\nsuper(jdbcConnection);\n}\n}\n</code></pre> <p>If there is no special configuration, just refer to the code to implement it, in <code>JdbcAdapter</code> we implement the specific JDBC conversion</p>"},{"location":"developer_guide/plugin.html#build-plugin","title":"Build Plugin","text":"<pre><code>package io.edurt.datacap.plugin.jdbc.kylin;\n\nimport io.edurt.datacap.spi.Plugin;\nimport io.edurt.datacap.spi.PluginType;\nimport io.edurt.datacap.spi.adapter.JdbcAdapter;\nimport io.edurt.datacap.spi.connection.JdbcConfigure;\nimport io.edurt.datacap.spi.connection.JdbcConnection;\nimport io.edurt.datacap.spi.model.Configure;\nimport io.edurt.datacap.spi.model.Response;\nimport lombok.extern.slf4j.Slf4j;\nimport org.apache.commons.beanutils.BeanUtils;\nimport org.apache.commons.lang3.ObjectUtils;\n\n@Slf4j\npublic class KylinPlugin\nimplements Plugin\n{\nprivate JdbcConfigure jdbcConfigure;\nprivate JdbcConnection connection;\nprivate Response response;\n\n@Override\npublic String name()\n{\nreturn \"Kylin\";\n}\n\n@Override\npublic String description()\n{\nreturn \"Integrate Kylin data sources\";\n}\n\n@Override\npublic PluginType type()\n{\nreturn PluginType.SOURCE;\n}\n\n@Override\npublic void connect(Configure configure)\n{\ntry {\nthis.response = new Response();\nthis.jdbcConfigure = new JdbcConfigure();\nBeanUtils.copyProperties(this.jdbcConfigure, configure);\nthis.jdbcConfigure.setJdbcDriver(\"org.apache.kylin.jdbc.Driver\");\nthis.jdbcConfigure.setJdbcType(\"kylin\");\nthis.connection = new JdbcConnection(this.jdbcConfigure, this.response);\n}\ncatch (Exception ex) {\nthis.response.setIsConnected(Boolean.FALSE);\nthis.response.setMessage(ex.getMessage());\n}\n}\n\n@Override\npublic Response execute(String content)\n{\nif (ObjectUtils.isNotEmpty(this.connection)) {\nlog.info(\"Execute kylin plugin logic started\");\nthis.response = this.connection.getResponse();\nJdbcAdapter processor = new KylinAdapter(this.connection);\nthis.response = processor.handlerExecute(content);\nlog.info(\"Execute kylin plugin logic end\");\n}\nreturn this.response;\n}\n\n@Override\npublic void destroy()\n{\nif (ObjectUtils.isNotEmpty(this.connection)) {\nthis.connection.destroy();\n}\n}\n}\n</code></pre> <p><code>implements Plugin</code> Implement the plug-in defined in the SPI system, what the specific plug-in implements.</p> <p>Note</p> <p><code>name()</code> The plug-in has a unique name, and plug-ins with the same name will only take effect the first time they are loaded  <code>type()</code> The type of plug-in  <code>description()</code> The description of the plug-in <code>connect(Configure configure)</code> The plug-in needs connection information in advance, such as the Kylin plugin, which is the connection stage of Kylin (the system presets the JDBC connection method to use it directly).  <code>execute(String content)</code> Specific execution operation logic  <code>destroy()</code> For the final destruction of the plug-in, note that the destruction needs to include information in the connection</p> <p>Note that in the <code>connect(Configure configure)</code> code we need to specify the driver and type of the connector, in the code we reset the <code>JdbcConfigure</code> that is, the specific JDBC configuration information The system will load it according to the specified driver, generate the format according to type as <code>jdbc:&lt;type&gt;xxxxxx</code> connection configuration, if it is a non-jdbc plug-in needs to implement the connection mode itself.</p> <p>In the <code>execute(String content)</code> stage we implement the system customization of the <code>JdbcAdapter</code> converter will automatically perform data assembly already packaged, etc., if it is a non-jdbc plug-in need to implement the converter itself.</p>"},{"location":"developer_guide/plugin.html#build-the-spi-configuration-plugin","title":"Build the SPI configuration plugin","text":"<p>Add the <code>META-INF</code> and <code>services</code> directories under the <code>resources</code> source directory</p> <p>Warning</p> <p><code>services</code> Required in the <code>resources</code> directory</p> <p>Create the <code>io.edurt.datacap.spi.PluginModule</code> file</p> <pre><code>io.edurt.datacap.plugin.jdbc.kylin.KylinPluginModule\n</code></pre> <p>The contents of the file are the plug-in loading modules that we have defined.</p> <p>Warning</p> <p>Unit tests of plug-ins can be tested with reference to plugins that have already been released</p>"},{"location":"reference/admin/datasource/home.html","title":"DataSource","text":"<p>Note</p> <p>Through the data source function, you can add support for various custom data sources, and perform subsequent data source operations, etc.</p>"},{"location":"reference/admin/datasource/home.html#add-data-source","title":"Add data source","text":"<p>After entering the system, click the corresponding <code>DataSource</code> submenu under the top <code>Admin</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the far right of the content area (it's a + icon), After clicking, the Add Data Source window will pop up as follows</p> <p></p> <p>When we select a certain type of data source, the data source configuration information will be displayed in the top tab bar</p> <p></p> <p>Fill in the relevant configuration information according to the data source tab. After the information is entered, click the <code>Test</code> button at the bottom. After the test is successful, you can click the <code>Save</code> button to save.</p> <p></p> <p>After the data source is saved, the data source list will be automatically refreshed, roughly as follows</p> <p></p>"},{"location":"reference/admin/datasource/home.html#modify-data-source","title":"Modify data source","text":"<p>Click the first button in <code>Action</code> in a data source in the list to modify the data source, the operation is similar to <code>Add data source</code> operation</p>"},{"location":"reference/admin/datasource/home.html#delete-data-source","title":"Delete data source","text":"<p>Click the second button in <code>Action</code> of a data source in the list to delete the data source, and the following content will pop up after clicking</p> <p></p> <p>Click the small window that pops up and click <code>OK</code> to delete the data source</p> <p>Danger</p> <p>It should be noted that after deleting the data source, the query history related to the data source will be deleted.</p>"},{"location":"reference/admin/datasource/home.html#data-source-management","title":"Data source management","text":"<p>Click the third button in <code>Action</code> of a data source in the list to jump to the data source management page.</p> <p></p> <p>The page is divided into left and right parts. The left side mainly displays the basic information of the data source, including:</p> <ul> <li>Database list</li> <li>Data table &amp; data column tree list</li> </ul> <p>When we select a database and a data table on the left, the content on the right is displayed as follows</p> <p></p> <p>Under the data table in the right content, you can select the previous page and next page operations of the current database table data.</p> <p>On the top right we can use the sorter to reorder the data</p> <p></p> <p>When we activate the sorter, we click the <code>Apply</code> button to apply the current sorter by selecting the data column and sorting rules, and the data below will be changed according to the sorter</p> <p>Danger</p> <p>If the current data source does not support the management function, the following page will be displayed</p> <p></p>"},{"location":"reference/admin/functions/home.html","title":"Functions","text":"<p>Note</p> <p>We can enhance the automatic prompt function of the code editor through the function module provided by the system.</p>"},{"location":"reference/admin/functions/home.html#system-default-function","title":"System default function","text":"<p>The system has built-in the following data source functions by default (it does not mean that it is the most complete function of the new version, if there is something missing, please submit issues or pr to fix it):</p> <ul> <li>ClickHouse</li> <li>MySQL</li> <li>Hive</li> <li>Trino &amp; Presto (fit a part)</li> </ul>"},{"location":"reference/admin/functions/home.html#add-function","title":"Add function","text":"<p>After entering the system, click the corresponding <code>Function</code> submenu under the top <code>Settings</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the top right to add a new function, and the following window will pop up after clicking:</p> <p></p> <p>The following is a detailed parameter description:</p> <ul> <li><code>Name</code>: The name used to mark the function prompt, the suggestion is English</li> <li><code>Plugin</code>: The plugin this function applies to, multiple options can be selected</li> <li><code>Content</code>: The specific content of the function, which will be entered into the editor</li> <li><code>Description</code>: Description of the function</li> <li><code>Type</code>: Type of function, can be: <code>KeyWord</code>, <code>Operator</code>, <code>Function</code>, default is <code>KeyWord</code></li> <li><code>Example</code>: For the use example of this function, it is convenient for users to understand how to use the function</li> </ul> <p>When the above content is written, click the <code>Submit</code> button at the bottom to save the operation, and you can use it in the editor later.</p>"},{"location":"reference/admin/functions/home.html#batch-operation","title":"Batch operation","text":"<p>The system provides a way to import functions in batches. Currently, it supports the import of content and URI addresses. Next, let's take a look at how to do it.</p> <p>We perform the batch import function by clicking the import button on the top right.</p>"},{"location":"reference/admin/functions/home.html#content-import","title":"Content import","text":"<p>The content import method allows us to enter a list of functions, and they are divided according to each line. Adding the following keywords we need to import:</p> <pre><code>SHOW\nUSE\n</code></pre> <p>In <code>Plugin</code>, we choose to use the <code>ClickHouse</code> plug-in, and in <code>Type</code>, we choose <code>KeyWord</code>. After the operation is completed, we click the <code>Submit</code> button at the bottom to use the import function of the current input function.</p>"},{"location":"reference/admin/functions/home.html#uri-import","title":"URI import","text":"<p>The URI import method is relatively simple. We can import data in batches by specifying the remote server URI address, which can be your local server address or the address provided by the software.</p> <p>The URI address format provided by the software by default is</p> <pre><code>(http|https)://datacap.edurt.io/resources/functions/plugin/keywords.txt\n(http|https)://datacap.edurt.io/resources/functions/plugin/operators.txt\n(http|https)://datacap.edurt.io/resources/functions/plugin/functions.txt\n</code></pre> <p>We only need to replace the value of plugin in the address with the name of the plugin that needs to be imported.</p> <p>Warning</p> <p>It should be noted that due to local network problems, the URI import method may be slow.</p>"},{"location":"reference/admin/processor/home.html","title":"Processor","text":"<p>Note</p> <p>Through the process monitoring function, you can view some specific processes currently being executed by the data source</p>"},{"location":"reference/admin/processor/home.html#view-all-processes","title":"View all processes","text":"<p>After entering the system, click the corresponding <code>Processor</code> submenu under the top <code>Admin</code> menu to go to the function configuration function</p> <p></p> <p>Select the data source we need to view the process through the drop-down box at the top, and it will be refreshed and displayed in the content area below</p> <p></p> <p>Danger</p> <p>It should be noted that different data sources have different presentation methods</p>"},{"location":"reference/admin/processor/home.html#not-support","title":"Not support","text":"<p>When we view the unsupported data source, the content of the page is as follows:</p> <p></p> <p>The system will prompt us to add SQL template or submit issues to support it</p>"},{"location":"reference/admin/snippet/home.html","title":"Snippet","text":"<p>Note</p> <p>Through the snippet function, you can add support for various custom snippet, and perform subsequent snippet operations, etc.</p>"},{"location":"reference/admin/snippet/home.html#add-snippet","title":"Add snippet","text":"<p>After entering the system, click the corresponding <code>Snippet</code> submenu under the top <code>Admin</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the far right of the content area (it's a + icon), After clicking, the Add snippet window will pop up as follows</p> <p></p> <p>In the window we need to enter the following</p> Field Description <code>Name</code> Tokenize the name of the current code snippet <code>Description</code> Description of the current code fragment <code>Snippet</code> The specific SQL content of the current code fragment <p>After filling in the above content, click the <code>Submit</code> button at the bottom to save the code snippet</p> <p>After the snippet is saved, the snippet list will be automatically refreshed, roughly as follows</p> <p></p>"},{"location":"reference/admin/snippet/home.html#view-snippet-content","title":"View snippet content","text":"<p>Click the first button in <code>Action</code> in a certain data in the list to view the specific code snippet content, it will pop up a dialog box, roughly as follows</p> <p></p> <p>Click <code>OK</code> or <code>Cancel</code> to close the dialog</p>"},{"location":"reference/admin/snippet/home.html#modify-snippet","title":"Modify snippet","text":"<p>Click the second button in <code>Action</code> in a data in the list to modify the snippet, the operation is similar to <code>Add snippet</code> operation</p>"},{"location":"reference/admin/snippet/home.html#quote-snippet","title":"Quote snippet","text":"<p>Click the third button in <code>Action</code> of a data in the list to reference the current code fragment, it will jump to the query page, and the fragment content will be directly input into the editor.</p>"},{"location":"reference/admin/snippet/home.html#delete-snippet","title":"Delete snippet","text":"<p>Click the fourth button in <code>Action</code> of a data in the list to delete the snippet, and the following content will pop up after clicking</p> <p></p> <p>Click the small window that pops up and click OK to delete the snippet</p>"},{"location":"reference/admin/template/sql/home.html","title":"Sql","text":"<p>Note</p> <p>The system supports the SQL template function, through which the realization of some monitoring and other functions can be supported.</p>"},{"location":"reference/admin/template/sql/home.html#default-template","title":"Default template","text":"<p>The system supports some default templates, currently supports:</p> <ul> <li><code>getAllDatabaseAndTable</code></li> <li><code>getAllDatabase</code></li> <li><code>getAllTablesFromDatabase</code></li> </ul> <p>Of course, each template can support one or more plug-ins, and they will be used in subsequent operations of the system.</p>"},{"location":"reference/admin/template/sql/home.html#add-template","title":"Add template","text":"<p>After entering the system, click the corresponding <code>Sql</code> submenu under the top <code>Settings</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the top right to add a new function, and the following window will pop up after clicking:</p> <p></p> <p>The following is a detailed parameter description:</p> <ul> <li><code>Name</code>: The name used to mark the function prompt, the suggestion is English</li> <li><code>Plugin</code>: The plugin this function applies to, multiple options can be selected</li> <li><code>Description</code>: Description of the function</li> <li><code>Template</code>: The SQL statement executed by the template</li> </ul> <p>When the above content is written, click the <code>Submit</code> button at the bottom to save the operation, and you can use it in the editor later.</p> <p>Warning</p> <p>The default template does not carry any parameters and we can execute it directly.</p>"},{"location":"reference/admin/template/sql/home.html#dynamic-parameter-template","title":"Dynamic parameter template","text":"<p>We can realize the template dynamic parameter passing function by defining variables. Let's take an example, we need to display all the data tables under the <code>default</code> database, the normal SQL is</p> <pre><code>SHOW TABLES FROM default\n</code></pre> <p>When we use the template, the SQL changes to</p> <pre><code>SHOW TABLES FROM ${database:String}\n</code></pre> <p>The system parses the parameter into <code>database=String</code> by collecting <code>{database:String}</code> expression, where <code>database</code> is the parameter name, and <code>String</code> is the type of parameter passing.</p> <p>When we use the expression time, we only need to pass the <code>Map</code> type parameter, where key=parameter name, value=data value passed according to the type.</p>"},{"location":"reference/clients/cli.html","title":"Command line interface","text":"<p>The DataCap CLI provides a terminal-based, interactive shell for running queries. The CLI is a self-executing JAR file, which means it acts like a normal UNIX executable.</p>"},{"location":"reference/clients/cli.html#requirements","title":"Requirements","text":"<p>The CLI requires a Java virtual machine available on the path. It can be used with Java version 8 and higher.</p> <p>The CLI uses the DataCap client REST API over HTTP/HTTPS to communicate with the system.</p> <p>The CLI version should be identical to the version of system, or newer.</p>"},{"location":"reference/clients/cli.html#installation","title":"Installation","text":"<p>Download datacap-client-cli-1.6.0.jar, rename it to datacap, make it executable with <code>chmod +x</code>.</p>"},{"location":"reference/clients/cli.html#running-the-cli","title":"Running the CLI","text":"<pre><code>./datacap\n\nconnect -h 127.0.0.1 -p 9096 -u username -P password\n</code></pre> <p>If successful, you will get a prompt to execute commands. Use the <code>help</code> command to see a list of supported commands.</p> Command Description <code>source info</code> Get data source details <code>source list</code> Get a list of remote server data sources <code>source use &lt;SourceID&gt;</code> Set the data source flag for subsequent operations on the data source <code>source execute \"&lt;QuerySQL&gt;\"</code> Execute remote SQL"},{"location":"reference/connectors/index.html","title":"Connectors","text":"<p>This chapter describes the connectors available in DataCap to access data from different data sources.</p>"},{"location":"reference/connectors/index.html#jdbc","title":"JDBC","text":"<p>DuckDB Yandex Database Snowflake MySQL ClickHouse </p>"},{"location":"reference/connectors/index.html#native","title":"Native","text":"<p>H2 Database Apache Kafka Aliyun OSS Apache Zookeeper Redis </p>"},{"location":"reference/connectors/index.html#http","title":"Http","text":"<p>ClickHouse </p>"},{"location":"reference/connectors/http/clickhouse.html","title":"ClickHouse","text":""},{"location":"reference/connectors/http/clickhouse.html#what-is-clickhouse","title":"What is ClickHouse ?","text":"<p>ClickHouse\u00ae is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP). ClickHouse\u2019s performance exceeds all other column-oriented database management systems. It processes billions of rows and tens of gigabytes of data per server per second.</p>"},{"location":"reference/connectors/http/clickhouse.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.3.x</code></p> <p>Support Time: <code>2022-11-09</code></p>"},{"location":"reference/connectors/http/clickhouse.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default clickhouse.json</p> <p>Note</p> <p>If your ClickHouse service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>8123</code>"},{"location":"reference/connectors/http/clickhouse.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 19.x</li> <li> 20.x</li> <li> 21.x</li> </ul>"},{"location":"reference/connectors/jdbc/clickhouse.html","title":"ClickHouse","text":""},{"location":"reference/connectors/jdbc/clickhouse.html#what-is-clickhouse","title":"What is ClickHouse ?","text":"<p>ClickHouse\u00ae is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP). ClickHouse\u2019s performance exceeds all other column-oriented database management systems. It processes billions of rows and tens of gigabytes of data per server per second.</p>"},{"location":"reference/connectors/jdbc/clickhouse.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.0.x</code></p> <p>Support Time: <code>2022-09-22</code></p>"},{"location":"reference/connectors/jdbc/clickhouse.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default clickhouse.json</p> <p>Note</p> <p>If your ClickHouse service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> - <p>Note</p> <p>You can add the already supported ClickHouse parameters by adding Key Value, the parameters can be reference document</p>"},{"location":"reference/connectors/jdbc/clickhouse.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 19.x</li> <li> 20.x</li> <li> 21.x</li> </ul>"},{"location":"reference/connectors/jdbc/duckdb.html","title":"DuckDB","text":""},{"location":"reference/connectors/jdbc/duckdb.html#what-is-duckdb","title":"What is DuckDB ?","text":"<p>DuckDB is an in-process SQL OLAP database management system.</p>"},{"location":"reference/connectors/jdbc/duckdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.6.x</code></p> <p>Support Time: <code>2023-02-20</code></p>"},{"location":"reference/connectors/jdbc/duckdb.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default duckdb.json</p> <p>Note</p> <p>If your DuckDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>/root</code> <code>Port</code> <code>0</code> Field Required Default Value <code>Database</code> <code>local</code>"},{"location":"reference/connectors/jdbc/duckdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 0.7.0</li> </ul>"},{"location":"reference/connectors/jdbc/mysql.html","title":"MySQL","text":""},{"location":"reference/connectors/jdbc/mysql.html#what-is-mysql","title":"What is MySQL ?","text":"<p>MySQL is one of the most recognizable technologies in the modern big data ecosystem. Often called the most popular database and currently enjoying widespread, effective use regardless of industry, it\u2019s clear that anyone involved with enterprise data or general IT should at least aim for a basic familiarity of MySQL.</p>"},{"location":"reference/connectors/jdbc/mysql.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.0.x</code></p> <p>Support Time: <code>2022-09-19</code></p>"},{"location":"reference/connectors/jdbc/mysql.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default mysql.json</p> <p>Note</p> <p>If your MySQL service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>3306</code> Field Required Default Value <code>Username</code> - <code>Password</code> - <code>SSL</code> <code>false</code> Field Required Default Value <code>Database</code> <code>default</code> <p>Note</p> <p>You can add the already supported MySQL parameters by adding Key Value, the parameters can be reference document</p> <p>Default:</p> Key value <code>useOldAliasMetadataBehavior</code> <code>true</code>"},{"location":"reference/connectors/jdbc/mysql.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 5.x</li> <li> 6.x</li> <li> 7.x</li> </ul>"},{"location":"reference/connectors/jdbc/snowflake.html","title":"Snowflake","text":""},{"location":"reference/connectors/jdbc/snowflake.html#what-is-snowflake","title":"What is Snowflake ?","text":"<p>Execute your most critical workloads on top of Snowflake's multi-cluster shared data architecture in a fully managed platform that capitalizes on the near-infinite resources of the cloud.</p>"},{"location":"reference/connectors/jdbc/snowflake.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.4.x</code></p> <p>Support Time: <code>2023-01-29</code></p>"},{"location":"reference/connectors/jdbc/snowflake.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default snowflake.json</p> <p>Note</p> <p>If your Snowflake service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>80</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> - <p>Note</p> <p>You can add the already supported Snowflake parameters by adding Key Value, the parameters can be reference document</p>"},{"location":"reference/connectors/jdbc/snowflake.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p>"},{"location":"reference/connectors/jdbc/ydb.html","title":"Yandex Database","text":""},{"location":"reference/connectors/jdbc/ydb.html#what-is-ydb","title":"What is YDB ?","text":"<p>YDB is a fault-tolerant distributed SQL DBMS. YDB provides high availability, horizontal scalability, strict consistency, and ACID transaction support. Queries are made using an SQL dialect (YQL).</p>"},{"location":"reference/connectors/jdbc/ydb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.4.x</code></p> <p>Support Time: <code>2023-01-30</code></p>"},{"location":"reference/connectors/jdbc/ydb.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default ydb.json</p> <p>Note</p> <p>If your YDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>2136</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> <code>local</code>"},{"location":"reference/connectors/jdbc/ydb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 2.1.x</li> </ul>"},{"location":"reference/connectors/native/alioss.html","title":"AliYun OSS","text":""},{"location":"reference/connectors/native/alioss.html#what-is-aliyun-oss","title":"What is Aliyun OSS ?","text":"<p>Fully managed object storage service to store and access any amount of data from anywhere</p>"},{"location":"reference/connectors/native/alioss.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.6.x</code></p> <p>Support Time: <code>2023-02-23</code></p>"},{"location":"reference/connectors/native/alioss.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in Aliyun OSS on DataCap.</p>"},{"location":"reference/connectors/native/alioss.html#select","title":"SELECT","text":"<p>Synopsis</p> <pre><code>SELECT [ * | &lt;Columns&gt; ] select_expression [, ...]\nFROM from_item [. ...]\n</code></pre> <p>where <code>from_item</code> is one of</p> <pre><code>table_name [ `a.b` | a.b | `a`.`b`]\n</code></pre> <p>Danger</p> <p>When <code>table_name</code> is set to <code>all</code> the root directory is searched.</p> <p>Select expressions</p> <p>Each <code>select_expression</code> must be in one of the following forms:</p> <pre><code>expression [ column_alias ]\n</code></pre> <pre><code>*\n</code></pre> <p>In the case of <code>expression [ column_alias ]</code>, a single output column is defined.</p> <p>In the case of <code>*</code>, all columns of the relation defined by the query are included in the result set.</p> <pre><code>    *\n--------\ndata\n</code></pre> <p>Danger</p> <p>If it is a multi-level directory, such as <code>/oss/id/2</code>, it will be written `oss`.`id`.`2`, and use <code>.</code> to split between directories.</p>"},{"location":"reference/connectors/native/alioss.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default alioss.json</p> <p>Note</p> <p>If your Aliyun OSS service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>https://oss-cn-regison.aliyuncs.com</code> Field Required Description Default Value <code>Username</code> access Id - <code>Password</code> access Secret - Field Required Description Default Value <code>Database</code> bucket name <code>default</code>"},{"location":"reference/connectors/native/alioss.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>all version</code></li> </ul>"},{"location":"reference/connectors/native/h2.html","title":"H2 Database","text":""},{"location":"reference/connectors/native/h2.html#what-is-h2","title":"What is h2 ?","text":"<p>H2 is an embedded database developed in Java that is itself just a class library. </p>"},{"location":"reference/connectors/native/h2.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.8.x</code></p> <p>Support Time: <code>2023-04-05</code></p>"},{"location":"reference/connectors/native/h2.html#configure","title":"Configure","text":"<p>Note</p> <p>If your h2 service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code>"},{"location":"reference/connectors/native/h2.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>all</code></li> </ul>"},{"location":"reference/connectors/native/redis.html","title":"Redis","text":""},{"location":"reference/connectors/native/redis.html#what-is-redis","title":"What is Redis ?","text":"<p>The open source, in-memory data store used by millions of developers as a database, cache, streaming engine, and message broker.</p>"},{"location":"reference/connectors/native/redis.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.3.x</code></p> <p>Support Time: <code>2022-12-01</code></p>"},{"location":"reference/connectors/native/redis.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default redis.json</p> <p>Note</p> <p>If your Redis service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorization Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>6379</code> Field Required Default Value <code>Password</code> -"},{"location":"reference/connectors/native/redis.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 6.x</li> <li> 7.x</li> </ul>"},{"location":"reference/connectors/native/zookeeper.html","title":"Apache Zookeeper","text":""},{"location":"reference/connectors/native/zookeeper.html#what-is-zookeeper","title":"What is Zookeeper ?","text":"<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. </p>"},{"location":"reference/connectors/native/zookeeper.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.5.x</code></p> <p>Support Time: <code>2023-02-07</code></p>"},{"location":"reference/connectors/native/zookeeper.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in Zookeeper on DataCap.</p>"},{"location":"reference/connectors/native/zookeeper.html#select","title":"SELECT","text":"<p>Synopsis</p> <pre><code>SELECT [ * | &lt;Columns&gt; ] select_expression [, ...]\nFROM from_item [. ...]\n</code></pre> <p>where <code>from_item</code> is one of</p> <pre><code>table_name [ `a.b` | a.b | `a`.`b`]\n</code></pre> <p>Danger</p> <p>When <code>table_name</code> is set to <code>all</code> the root directory is searched.</p> <p>Select expressions</p> <p>Each <code>select_expression</code> must be in one of the following forms:</p> <pre><code>expression [ column_alias ]\n</code></pre> <pre><code>*\n</code></pre> <p>In the case of <code>expression [ column_alias ]</code>, a single output column is defined.</p> <p>In the case of <code>*</code>, all columns of the relation defined by the query are included in the result set.</p> <pre><code>    *\n--------\ndata\n</code></pre> <p>Danger</p> <p>If it is a multi-level directory, such as <code>/zookeeper/id/2</code>, it will be written `zookeeper`.`id`.`2`, and use <code>.</code> to split between directories.</p>"},{"location":"reference/connectors/native/zookeeper.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default zookeeper.json</p> <p>Note</p> <p>If your Zookeeper service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1:2181</code> <code>Port</code> <code>1</code>"},{"location":"reference/connectors/native/zookeeper.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>3.1.x</code> - <code>3.7.x</code></li> </ul>"},{"location":"reference/connectors/native/kafka/index.html","title":"Apache Kafka","text":""},{"location":"reference/connectors/native/kafka/index.html#what-is-apache-kafka","title":"What is Apache Kafka ?","text":"<p>Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.</p>"},{"location":"reference/connectors/native/kafka/index.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.7.x</code></p> <p>Support Time: <code>2023-03-06</code></p>"},{"location":"reference/connectors/native/kafka/index.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in DataCap Kafka plugin.</p> <p>SHOW TOPICS SHOW CONSUMERS</p>"},{"location":"reference/connectors/native/kafka/index.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default kafka.json</p> <p>Note</p> <p>If your Apache Kafka service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>localhost:9092</code>"},{"location":"reference/connectors/native/kafka/index.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>1.0.0</code></li> <li> <code>1.1.0</code></li> <li> <code>1.2.0</code></li> </ul>"},{"location":"reference/get_started/history.html","title":"Query History","text":"<p>When we use the system for the first time or need to add a new data source, click the top menu <code>Admin</code> -&gt; <code>History</code> and it will jump to the query history management page, its layout is as follows</p> <p></p> <p>After entering the page by default, the query history list of all added data sources is displayed.</p> <code>No</code> Data number <code>Plugin</code> The data source to call <code>Create Time</code> Creation time <code>End Time</code> End Time <code>Elapsed</code> Total time spent <code>State</code> Status <code>Action</code> Additional operation"},{"location":"reference/get_started/history.html#additional-operation","title":"Additional operation","text":"<p>Currently there are two additional operations:</p>"},{"location":"reference/get_started/history.html#view-execution-sql","title":"View execution SQL","text":"<p>Click  button\uff0cthe following window will pop up</p> <p></p> <p>The specific SQL statement queried in this query is displayed in the window</p>"},{"location":"reference/get_started/history.html#view-execution-errors","title":"View execution errors","text":"<p>click  button will pop up the following window</p> <p></p> <p>The specific error information of this query is displayed in the window, which is only available when this query fails</p>"},{"location":"reference/get_started/install.html","title":"Deploying DataCap","text":"<p>DataCap is a software for data transformation, integration and visualization.</p>"},{"location":"reference/get_started/install.html#system-requirements","title":"System Requirements","text":"<p>Warning</p> <p>The binary package of the software is compiled and tested based on the following systems. It has not been tested on other versions, and it is theoretically supported.</p> <p>If there is an unsupported system, use the source code compilation method to actively compile the binary file.</p> System Version JDK <code>&gt;=11</code> MySQL <code>&gt;=5.6.x</code>"},{"location":"reference/get_started/install.html#binary-install","title":"Binary install","text":"<p>Note</p> <p>Download the binary software package of the corresponding system from the following address for installation.</p> <ul> <li>Download Release</li> </ul>"},{"location":"reference/get_started/install.html#download-package","title":"Download package","text":"<p>Run the following command after downloading the binary to your local</p> <pre><code>tar -xvzf datacap-&lt;VERSION&gt;-release.tar.gz\n</code></pre> <p><code>VERSION</code> After referring to the downloaded binary file version</p>"},{"location":"reference/get_started/install.html#configuration-software","title":"Configuration software","text":"<p>Warning</p> <p>If MySQL is not configured for the first installation, the h2 built-in database will be used by default.</p> <p>For the first installation of the software, you need to import the sql scripts in the <code>schema/datacap.sql</code> file to the MySQL server. Note that the scripts that need to be imported are matched according to the downloaded software package</p> <p>After importing the <code>SQL</code> script, modify the <code>configure/application.properties</code> configuration file to modify the configuration information of the MySQL server</p> <p>If MySQL, Remove configuration</p> <pre><code>spring.datasource.driverClassName=org.h2.Driver\nspring.datasource.url=jdbc:h2:mem:datacap\nspring.datasource.username=h2\nspring.datasource.password=h2\nspring.jpa.database-platform=org.hibernate.dialect.H2Dialect\nspring.h2.console.enabled=true\n</code></pre> <p>Add configuration</p> <pre><code>spring.datasource.url=jdbc:mysql://localhost:3306/datacap?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false&amp;useOldAliasMetadataBehavior=true&amp;jdbcCompliantTruncation=false&amp;sessionVariables=sql_mode='STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,PIPES_AS_CONCAT'\nspring.datasource.username=root\nspring.datasource.password=12345678\n</code></pre> <p>Warning</p> <p>If you need to modify the log configuration, just modify the <code>configure/logback.xml</code> configuration file</p>"},{"location":"reference/get_started/install.html#start-service","title":"Start service","text":"<p>DataCap service startup is very simple, execute the following script</p> <pre><code>./bin/startup.sh\n</code></pre>"},{"location":"reference/get_started/install.html#stop-service","title":"Stop service","text":"<p>Stop the service and execute the following script</p> <pre><code>./bin/shutdown.sh\n</code></pre> <p>Note</p> <p>If you want to debug the system, you can use <code>./bin/debug.sh</code> to start the service, but it will stop when you close the window</p>"},{"location":"reference/get_started/install.html#source-installation","title":"Source installation","text":"<p>Warning</p> <p>To manually compile and install DataCap, you need to perform the following steps.</p> <p>The system needs to install <code>JDK</code></p> <ul> <li>Clone the source code to this machine</li> </ul> <pre><code>git clone https://github.com/EdurtIO/datacap.git\n</code></pre> <ul> <li>Compile and build the application</li> </ul> <pre><code>./mvnw clean install package -DskipTests\n</code></pre> <p>Warning</p> <p>After compiling, the <code>datacap-release.tar.gz</code> package will be generated in the <code>dist</code> directory.</p> <p>Use the relevant packages to install it.</p> <p>Note</p> <p>If you do not want to install to the local software directory, you can use the following documents to start the development mode for software use.</p> <p>Developer</p>"},{"location":"reference/get_started/install_containers.html","title":"DataCap in a Docker container","text":"<p>The DataCap project provides the qianmoq/datacap Docker image that includes the DataCap server and a default configuration. The Docker image is published to Docker Hub and can be used with the Docker runtime, among several others.</p>"},{"location":"reference/get_started/install_containers.html#running-the-container","title":"Running the container","text":"<p>To run DataCap in Docker, you must have the Docker engine installed on your machine. You can download Docker from the Docker website, or use the packaging system of your operating systems.</p> <p>Use the docker command to create a container from the qianmoq/datacap image. Assign it the datacap name, to make it easier to reference it later. Run it in the background, and map the default DataCap port, which is <code>9096</code>, from inside the container to port <code>9096</code> on your workstation.</p> <pre><code>docker run -d -p 9909:9096 --name datacap qianmoq/datacap\n</code></pre> <p>Without specifying the container image tag, it defaults to <code>latest</code>, but a number of any released DataCap version can be used, for example <code>qianmoq/datacap:1.8.0</code>.</p> <p>Run <code>docker ps</code> to see all the containers running in the background.</p> <pre><code>-&gt; % docker ps\nCONTAINER ID   IMAGE                    COMMAND               CREATED      STATUS          PORTS                    NAMES\n2096fba19e2a   datacap:latest           \"sh ./bin/debug.sh\"   5 days ago   Up 14 seconds   0.0.0.0:9909-&gt;9096/tcp   datacap\n</code></pre>"},{"location":"reference/get_started/install_containers.html#cleaning-up","title":"Cleaning up","text":"<p>You can stop and start the container, using the <code>docker stop datacap</code> and <code>docker start datacap</code> commands. To fully remove the stopped container, run docker rm datacap.</p>"},{"location":"reference/get_started/query.html","title":"Query","text":"<p>After entering the software UI interface, click the <code>Query</code> menu option at the top, and you will enter a page similar to the following:</p> <p></p>"},{"location":"reference/get_started/query.html#description","title":"Description","text":"<p>The query page is divided into two parts: the upper part is the SQL editor, and the lower part is the query result</p> <p></p> <p>There are 4 function boxes at the top of the editor, they are:</p> <ul> <li>The first one: <code>selection box</code> is used to select the data source we have created</li> <li>The second: <code>button</code> is to perform the operation</li> <li>The third: <code>button</code> is to format the SQL content we entered</li> <li>The fourth: <code>button</code> is used to cancel the query that takes too long to execute</li> </ul> <p>Danger</p> <p>The cancel function does not mean that the actual query is over, and the query will continue to run in the background.</p>"},{"location":"reference/get_started/query.html#example","title":"Example","text":"<p>We use the following SQL for testing</p> <pre><code>show databases\n</code></pre> <p>After we write the SQL into the editor, click the second function button at the top of the editor to run it. After running, a window similar to the following will be displayed:</p> <p></p> <p>The result window is divided into: the top menu is the data export function, which currently supports <code>CSV</code> export, and the lower part is the data result display.</p> <p>Note</p> <p>The specific result display content is returned according to the SQL query by the user</p>"},{"location":"reference/get_started/query.html#data-output","title":"Data output","text":"<p>Move the mouse to the top menu of the result display area, and a drop-down box will appear. Click the type to be exported, and a download dialog box will pop up, and the data can be downloaded to the local.</p>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html","title":"SHOW CONSUMERS","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW CONSUMERS\nSHOW CONSUMERS FROM topic\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html#description","title":"Description","text":"<p>Returns a list of all defined consumers in the current cluster (if a topic is specified, a list of consumers for the specified topic will be returned). Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html","title":"SHOW DATABASES","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW DATABASES\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html#description","title":"Description","text":"<p>Returns a list of all defined topics in the current cluster. Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html","title":"SHOW TABLES","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW TABLES\nSHOW TABLES FROM `database`\n</code></pre> <p><code>database</code> kafka topic name</p>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html#description","title":"Description","text":"<p>Returns a list of all defined consumers in the current cluster (if a topic is specified, a list of consumers for the specified topic will be returned). Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html","title":"SHOW TOPICS","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW TOPICS\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html#description","title":"Description","text":"<p>Returns a list of all defined topics in the current cluster. Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"release/1.0.0.20221015.html","title":"1.0.0.20221015","text":"<p>Note</p> <p>This is the first new version we've released.</p> <p> DataCap is released </p> Release Version Release Time <code>1.0.0.20221015</code> <code>2022-10-15</code>"},{"location":"release/1.0.0.20221015.html#general","title":"General","text":"<ul> <li>Building SPI supports multiple data sources</li> <li>Supports web visualization based on Vue architecture</li> <li>Support Data source usage history</li> <li>Data statistics for data sources and history</li> </ul>"},{"location":"release/1.0.0.20221015.html#plugins","title":"Plugins","text":"<ul> <li> Support ClickHouse</li> <li> Support MySQL</li> <li> Support Presto</li> <li> Support Redis</li> <li> Support PostgreSQL</li> <li> Support Trino</li> <li> Support ElasticSearch</li> <li> Support Apache Druid</li> <li> Support Apache Kyuubi</li> <li> Support Apache Hive</li> <li> Support Apache Kylin</li> <li> Support Apache Ignite</li> <li> Support IBM DB2</li> </ul>"},{"location":"release/1.0.0.20221015.html#thank-you","title":"Thank you","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @mlboy @qianmoQ"},{"location":"release/1.1.0.20221115.html","title":"1.1.0.20221115","text":"<p>Note</p> <p>The current release involves several major updates. The following link is Roadmap</p> <p> DataCap is released </p> Release Version Release Time <code>1.1.0.20221115</code> <code>2022-11-15</code>"},{"location":"release/1.1.0.20221115.html#general","title":"General","text":"<ul> <li>Replace plugin name to id</li> <li>Support for internationalization issues-82</li> <li>Reduce size of docker image</li> <li>Switch bash docker image to eclipse-temurin:8-jdk-focal</li> <li>Support ssl issues-75</li> <li>Extract the plug-in to get the global tool</li> <li>Support database write operation issues-70</li> <li>Supports user rights management</li> <li>Support code snippet issues-74</li> <li>Support editor auto completion</li> <li>Support to provide data source schema tree bar issues-106</li> <li>Support multiple editor issues-110</li> <li>Add profile for user</li> <li>Support change user password</li> <li>Add data source radar map within 7 days</li> <li>Add about page</li> <li>Add feedback issues-126</li> </ul>"},{"location":"release/1.1.0.20221115.html#spi","title":"SPI","text":"<ul> <li>Add custom validator</li> </ul>"},{"location":"release/1.1.0.20221115.html#plugins","title":"Plugins","text":"<ul> <li>Support MongoDB</li> <li>Support Dremio</li> <li>Support HBase jdbc for Phoenix issues-103</li> <li>Support H2</li> <li>Support SqlServer</li> <li>Support Oracle</li> </ul>"},{"location":"release/1.1.0.20221115.html#redis","title":"Redis","text":"<ul> <li>Fix cannot init RedisConnection issues-71</li> </ul>"},{"location":"release/1.1.0.20221115.html#elasticsearch","title":"ElasticSearch","text":"<ul> <li>Update version to <code>7.10.0</code></li> </ul>"},{"location":"release/1.1.0.20221115.html#kyuubi","title":"Kyuubi","text":"<ul> <li>Bump Kyuubi <code>1.6.0-incubating</code></li> </ul>"},{"location":"release/1.1.0.20221115.html#thank-you","title":"Thank you","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @pan3793 @javalover123 @shuangzishuai @GtoCm @why198852 @qianmoQ"},{"location":"release/1.2.0.html","title":"1.2.0","text":"<p>Note</p> <p>The current release involves several major updates. The following link is Roadmap</p> <p> DataCap is released </p> Release Version Release Time <code>1.2.0</code> <code>2022-11-30</code>"},{"location":"release/1.2.0.html#general","title":"General","text":"<ul> <li>Support http protocol</li> </ul>"},{"location":"release/1.2.0.html#web","title":"Web","text":"<ul> <li>Support for data result column header hiding (#139)</li> <li>Support data result filtering (#132 #140)</li> <li>Replace <code>@antv/g2</code> to <code>echarts</code></li> <li>Replace <code>ant-design-vue</code> to <code>iview</code></li> <li>Replace <code>@antv/s2</code> to <code>ag-grid</code></li> <li>Optimize about page</li> <li>Optimize not found page</li> <li>Add not authorized page</li> <li>Add version badge</li> <li>Add not network page</li> <li>Support result visual line chart</li> </ul>"},{"location":"release/1.2.0.html#plugins","title":"Plugins","text":"<ul> <li>Support cratedb</li> <li>Support cratedb for http</li> <li>Support dameng</li> <li>Support clickhouse for http</li> <li>Support tdengine for jdbc</li> <li>Support impala for jdbc</li> </ul>"},{"location":"release/1.2.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.3.0.html","title":"1.3.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.3.0</code> <code>2022-12-16</code>"},{"location":"release/1.3.0.html#general","title":"General","text":"<ul> <li>Support change username</li> <li>Support custom sql template</li> <li>Support plugin function</li> <li>Add restart script</li> </ul>"},{"location":"release/1.3.0.html#web","title":"Web","text":"<ul> <li>Optimize the presentation of the data source list</li> <li>Add data source description and prompt</li> <li>Support query history id order</li> <li>Support quote query history</li> </ul>"},{"location":"release/1.3.0.html#plugins","title":"Plugins","text":"<ul> <li>Support oceanbase for jdbc</li> <li>Support redis for native</li> <li>Support neo4j for jdbc</li> <li>Support iotdb for jdbc</li> </ul>"},{"location":"release/1.3.0.html#redis","title":"Redis","text":"<ul> <li>Support auth for native</li> </ul>"},{"location":"release/1.3.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.4.0.html","title":"1.4.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.4.0</code> <code>2023-01-31</code>"},{"location":"release/1.4.0.html#general","title":"General","text":"<ul> <li>Fixed restart script</li> <li>Supports monitor process</li> <li>Do not modify the default system SQL template</li> <li>Fixed plugin template by name</li> <li>Support user login log</li> <li>Refactoring plug-in configuration extraction mode</li> </ul>"},{"location":"release/1.4.0.html#experimental","title":"Experimental","text":"<ul> <li>Support data source manager</li> <li>Add client cli</li> </ul>"},{"location":"release/1.4.0.html#web","title":"Web","text":"<ul> <li>Plug-in ICONS are displayed based on the plug-in type</li> <li>Optimize editor auto prompt</li> <li>Support watermark</li> <li>Templates are not supported for adding data sources</li> <li>Fixed footer link</li> </ul>"},{"location":"release/1.4.0.html#plugins","title":"Plugins","text":"<ul> <li>Support snowflake for jdbc</li> <li>Support ydb for jdbc</li> </ul>"},{"location":"release/1.4.0.html#docs","title":"Docs","text":"<ul> <li>Refactor some docs</li> </ul>"},{"location":"release/1.4.0.html#redis-native","title":"Redis (Native)","text":"<ul> <li>Fixed command multiple parameters</li> </ul>"},{"location":"release/1.4.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ @hometownglory"},{"location":"release/1.5.0.html","title":"1.5.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.5.0</code> <code>2023-02-16</code>"},{"location":"release/1.5.0.html#general","title":"General","text":"<ul> <li>Support dsl query</li> <li>Remove incubator</li> <li>Add sql parser</li> <li>Refactor the module directories</li> <li>Set port default value is 0</li> </ul>"},{"location":"release/1.5.0.html#spi","title":"SPI","text":"<ul> <li>Fixed jdbc no password exception is configured</li> </ul>"},{"location":"release/1.5.0.html#web","title":"Web","text":"<ul> <li>Support multi column sort</li> </ul>"},{"location":"release/1.5.0.html#plugins","title":"Plugins","text":"<ul> <li>Support zookeeper for native</li> </ul>"},{"location":"release/1.5.0.html#docs","title":"Docs","text":"<ul> <li>Add powered by page</li> </ul>"},{"location":"release/1.5.0.html#redis-native","title":"Redis (Native)","text":"<ul> <li>Fixed mget,hget value is displayed as null #219</li> </ul>"},{"location":"release/1.5.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump maven-javadoc-plugin from 2.10.4 to 3.4.1</li> <li>Bump ojdbc8 from 21.1.0.0 to 21.9.0.0</li> <li>Bump mongodb-jdbc from 2.0.0 to 2.0.2</li> </ul>"},{"location":"release/1.5.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.6.0.html","title":"1.6.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.6.0</code> <code>2023-03-02</code>"},{"location":"release/1.6.0.html#general","title":"General","text":"<ul> <li>Add logo</li> <li>Support <code>SHOW PATHS xxx</code></li> <li>Fixed function time field</li> <li>Refactor all module</li> <li>Add http lib</li> <li>Add logger lib</li> </ul>"},{"location":"release/1.6.0.html#spi","title":"SPI","text":"<ul> <li>JDBC: Repair Connection failure Do not close the connection</li> </ul>"},{"location":"release/1.6.0.html#web","title":"Web","text":"<ul> <li>Add default watermark</li> <li>Remove about page</li> <li>Add routing permission control</li> <li>Optimize lazy loading of the tree menu of the query page</li> </ul>"},{"location":"release/1.6.0.html#plugins","title":"Plugins","text":"<ul> <li>Support duckdb for jdbc close #249</li> <li>Support alioss for native #250</li> </ul>"},{"location":"release/1.6.0.html#zookeeper-native","title":"Zookeeper (Native)","text":"<ul> <li>Support <code>SHOW PATHS</code></li> </ul>"},{"location":"release/1.6.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump maven-javadoc-plugin from <code>3.4.1</code> to <code>3.5.1</code></li> <li>Bump oceanbas-client from <code>2.4.0</code> to <code>2.4.2</code></li> </ul>"},{"location":"release/1.6.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @why198852 @mlboy @qianmoQ"},{"location":"release/1.7.0.html","title":"1.7.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.7.0</code> <code>2023-03-20</code>"},{"location":"release/1.7.0.html#general","title":"General","text":"<ul> <li>Add other issues template</li> <li>Add role</li> <li>Upgrade JDK <code>8</code> to <code>11</code></li> <li>Support chatgpt</li> <li>Add submit pipeline api</li> </ul>"},{"location":"release/1.7.0.html#experimental","title":"Experimental","text":"<ul> <li>Add seatunnel executor</li> </ul>"},{"location":"release/1.7.0.html#client","title":"Client","text":"<ul> <li>Support execute sql on source</li> <li>Fixed code bugs</li> </ul>"},{"location":"release/1.7.0.html#docs","title":"Docs","text":"<ul> <li>Add icon to connectors</li> </ul>"},{"location":"release/1.7.0.html#spi","title":"SPI","text":"<ul> <li>Add executor spi</li> </ul>"},{"location":"release/1.7.0.html#web","title":"Web","text":"<ul> <li>Fixed duplicate tree menu data</li> <li>Optimized type display icon</li> <li>Optimize data source testing\uff5csave interaction</li> <li>Support query history display plug-in type</li> <li>Add system announcement display</li> <li>Fixed the 'keyword' is repeated with tab page addition bug #208</li> <li>Replace markdown preview component</li> </ul>"},{"location":"release/1.7.0.html#plugins","title":"Plugins","text":"<ul> <li>Support kafka</li> </ul>"},{"location":"release/1.7.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Upgrade redis version from <code>3.6.3</code> to <code>4.3.1</code></li> <li>Bump maven-assembly-plugin from <code>3.1.1</code> to <code>3.5.0</code> #272</li> <li>Bump antlr4.version from <code>4.9.3</code> to <code>4.12.0</code> #262</li> <li>Bump jedis from <code>3.6.3</code> to <code>4.3.1</code> #254</li> <li>Bump DmJdbcDriver18 from <code>8.1.2.141</code> to <code>8.1.2.192</code> #234</li> </ul>"},{"location":"release/1.7.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @why198852 @Stacey1018 @qianmoQ"},{"location":"release/latest.html","title":"1.8.0 (latest)","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.8.0</code> <code>2023-04-10</code>"},{"location":"release/latest.html#general","title":"General","text":"<ul> <li>Rename executor directory</li> <li>Optimize document release timing</li> <li>Fixed format connect url close #304</li> <li>Support proxy for chatgpt close #299</li> <li>ChatGPT is currently unable to associate context close #298</li> <li>Support returning parsing error results</li> <li>Add schedule lib</li> <li>Support the code editor supports automatic prompts for data source library tables and columns close #301</li> <li>Fix initialization sql script</li> <li>Support h2 database</li> <li>Remove some invalid jars</li> <li>Add docker publish ci</li> </ul>"},{"location":"release/latest.html#docs","title":"Docs","text":"<ul> <li>Refactor install docs</li> </ul>"},{"location":"release/latest.html#web","title":"Web","text":"<ul> <li>The code editor supports code fragments close #300</li> </ul>"},{"location":"release/latest.html#plugins","title":"Plugins","text":"<ul> <li>Support h2 for native (memory)</li> </ul>"},{"location":"release/latest.html#kafka","title":"Kafka","text":"<ul> <li>Perfect test case</li> <li>Support <code>SHOW DATABASES</code> and <code>SHOW TABLES</code> ...</li> </ul>"},{"location":"release/latest.html#oracle","title":"Oracle","text":"<ul> <li>Fixed validation sql content</li> </ul>"},{"location":"release/latest.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump jackson.version from <code>2.13.4</code> to <code>2.14.2</code></li> <li>Bump postgresql from <code>42.5.0</code> to <code>42.6.0</code></li> </ul>"},{"location":"release/latest.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"resources/functions/home.html","title":"Functions","text":"<ul> <li> <p>ClickHouse</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>MySQL</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>Hive</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>Trino &amp; Presto</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> </ul>"}]}